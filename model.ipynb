{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.class_embedding = nn.Parameter(10 * torch.randn(10))\n",
    "        self.ln_pre = nn.LayerNorm(180)\n",
    "\n",
    "a = Test()\n",
    "a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Test()\n",
    "b.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p1,p2 in zip(a.parameters(),b.parameters()):\n",
    "    print(p1.data,p2.data)\n",
    "    print(p1.data+p2.data)\n",
    "    p1.data = p1.data+p2.data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/od/anaconda3/envs/dfd-clip/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.load(\"/home/od/Desktop/repos/dfd-clip/logs/comp-inv/comp-inv/0503T1230/last_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder.class_embedding', 'encoder.positional_embedding', 'encoder.proj', 'encoder.conv1.weight', 'encoder.ln_pre.weight', 'encoder.ln_pre.bias', 'encoder.transformer.resblocks.0.attn.in_proj_weight', 'encoder.transformer.resblocks.0.attn.in_proj_bias', 'encoder.transformer.resblocks.0.attn.out_proj.weight', 'encoder.transformer.resblocks.0.attn.out_proj.bias', 'encoder.transformer.resblocks.0.ln_1.weight', 'encoder.transformer.resblocks.0.ln_1.bias', 'encoder.transformer.resblocks.0.mlp.c_fc.weight', 'encoder.transformer.resblocks.0.mlp.c_fc.bias', 'encoder.transformer.resblocks.0.mlp.c_proj.weight', 'encoder.transformer.resblocks.0.mlp.c_proj.bias', 'encoder.transformer.resblocks.0.ln_2.weight', 'encoder.transformer.resblocks.0.ln_2.bias', 'encoder.transformer.resblocks.1.attn.in_proj_weight', 'encoder.transformer.resblocks.1.attn.in_proj_bias', 'encoder.transformer.resblocks.1.attn.out_proj.weight', 'encoder.transformer.resblocks.1.attn.out_proj.bias', 'encoder.transformer.resblocks.1.ln_1.weight', 'encoder.transformer.resblocks.1.ln_1.bias', 'encoder.transformer.resblocks.1.mlp.c_fc.weight', 'encoder.transformer.resblocks.1.mlp.c_fc.bias', 'encoder.transformer.resblocks.1.mlp.c_proj.weight', 'encoder.transformer.resblocks.1.mlp.c_proj.bias', 'encoder.transformer.resblocks.1.ln_2.weight', 'encoder.transformer.resblocks.1.ln_2.bias', 'encoder.transformer.resblocks.2.attn.in_proj_weight', 'encoder.transformer.resblocks.2.attn.in_proj_bias', 'encoder.transformer.resblocks.2.attn.out_proj.weight', 'encoder.transformer.resblocks.2.attn.out_proj.bias', 'encoder.transformer.resblocks.2.ln_1.weight', 'encoder.transformer.resblocks.2.ln_1.bias', 'encoder.transformer.resblocks.2.mlp.c_fc.weight', 'encoder.transformer.resblocks.2.mlp.c_fc.bias', 'encoder.transformer.resblocks.2.mlp.c_proj.weight', 'encoder.transformer.resblocks.2.mlp.c_proj.bias', 'encoder.transformer.resblocks.2.ln_2.weight', 'encoder.transformer.resblocks.2.ln_2.bias', 'encoder.transformer.resblocks.3.attn.in_proj_weight', 'encoder.transformer.resblocks.3.attn.in_proj_bias', 'encoder.transformer.resblocks.3.attn.out_proj.weight', 'encoder.transformer.resblocks.3.attn.out_proj.bias', 'encoder.transformer.resblocks.3.ln_1.weight', 'encoder.transformer.resblocks.3.ln_1.bias', 'encoder.transformer.resblocks.3.mlp.c_fc.weight', 'encoder.transformer.resblocks.3.mlp.c_fc.bias', 'encoder.transformer.resblocks.3.mlp.c_proj.weight', 'encoder.transformer.resblocks.3.mlp.c_proj.bias', 'encoder.transformer.resblocks.3.ln_2.weight', 'encoder.transformer.resblocks.3.ln_2.bias', 'encoder.transformer.resblocks.4.attn.in_proj_weight', 'encoder.transformer.resblocks.4.attn.in_proj_bias', 'encoder.transformer.resblocks.4.attn.out_proj.weight', 'encoder.transformer.resblocks.4.attn.out_proj.bias', 'encoder.transformer.resblocks.4.ln_1.weight', 'encoder.transformer.resblocks.4.ln_1.bias', 'encoder.transformer.resblocks.4.mlp.c_fc.weight', 'encoder.transformer.resblocks.4.mlp.c_fc.bias', 'encoder.transformer.resblocks.4.mlp.c_proj.weight', 'encoder.transformer.resblocks.4.mlp.c_proj.bias', 'encoder.transformer.resblocks.4.ln_2.weight', 'encoder.transformer.resblocks.4.ln_2.bias', 'encoder.transformer.resblocks.5.attn.in_proj_weight', 'encoder.transformer.resblocks.5.attn.in_proj_bias', 'encoder.transformer.resblocks.5.attn.out_proj.weight', 'encoder.transformer.resblocks.5.attn.out_proj.bias', 'encoder.transformer.resblocks.5.ln_1.weight', 'encoder.transformer.resblocks.5.ln_1.bias', 'encoder.transformer.resblocks.5.mlp.c_fc.weight', 'encoder.transformer.resblocks.5.mlp.c_fc.bias', 'encoder.transformer.resblocks.5.mlp.c_proj.weight', 'encoder.transformer.resblocks.5.mlp.c_proj.bias', 'encoder.transformer.resblocks.5.ln_2.weight', 'encoder.transformer.resblocks.5.ln_2.bias', 'encoder.transformer.resblocks.6.attn.in_proj_weight', 'encoder.transformer.resblocks.6.attn.in_proj_bias', 'encoder.transformer.resblocks.6.attn.out_proj.weight', 'encoder.transformer.resblocks.6.attn.out_proj.bias', 'encoder.transformer.resblocks.6.ln_1.weight', 'encoder.transformer.resblocks.6.ln_1.bias', 'encoder.transformer.resblocks.6.mlp.c_fc.weight', 'encoder.transformer.resblocks.6.mlp.c_fc.bias', 'encoder.transformer.resblocks.6.mlp.c_proj.weight', 'encoder.transformer.resblocks.6.mlp.c_proj.bias', 'encoder.transformer.resblocks.6.ln_2.weight', 'encoder.transformer.resblocks.6.ln_2.bias', 'encoder.transformer.resblocks.7.attn.in_proj_weight', 'encoder.transformer.resblocks.7.attn.in_proj_bias', 'encoder.transformer.resblocks.7.attn.out_proj.weight', 'encoder.transformer.resblocks.7.attn.out_proj.bias', 'encoder.transformer.resblocks.7.ln_1.weight', 'encoder.transformer.resblocks.7.ln_1.bias', 'encoder.transformer.resblocks.7.mlp.c_fc.weight', 'encoder.transformer.resblocks.7.mlp.c_fc.bias', 'encoder.transformer.resblocks.7.mlp.c_proj.weight', 'encoder.transformer.resblocks.7.mlp.c_proj.bias', 'encoder.transformer.resblocks.7.ln_2.weight', 'encoder.transformer.resblocks.7.ln_2.bias', 'encoder.transformer.resblocks.8.attn.in_proj_weight', 'encoder.transformer.resblocks.8.attn.in_proj_bias', 'encoder.transformer.resblocks.8.attn.out_proj.weight', 'encoder.transformer.resblocks.8.attn.out_proj.bias', 'encoder.transformer.resblocks.8.ln_1.weight', 'encoder.transformer.resblocks.8.ln_1.bias', 'encoder.transformer.resblocks.8.mlp.c_fc.weight', 'encoder.transformer.resblocks.8.mlp.c_fc.bias', 'encoder.transformer.resblocks.8.mlp.c_proj.weight', 'encoder.transformer.resblocks.8.mlp.c_proj.bias', 'encoder.transformer.resblocks.8.ln_2.weight', 'encoder.transformer.resblocks.8.ln_2.bias', 'encoder.transformer.resblocks.9.attn.in_proj_weight', 'encoder.transformer.resblocks.9.attn.in_proj_bias', 'encoder.transformer.resblocks.9.attn.out_proj.weight', 'encoder.transformer.resblocks.9.attn.out_proj.bias', 'encoder.transformer.resblocks.9.ln_1.weight', 'encoder.transformer.resblocks.9.ln_1.bias', 'encoder.transformer.resblocks.9.mlp.c_fc.weight', 'encoder.transformer.resblocks.9.mlp.c_fc.bias', 'encoder.transformer.resblocks.9.mlp.c_proj.weight', 'encoder.transformer.resblocks.9.mlp.c_proj.bias', 'encoder.transformer.resblocks.9.ln_2.weight', 'encoder.transformer.resblocks.9.ln_2.bias', 'encoder.transformer.resblocks.10.attn.in_proj_weight', 'encoder.transformer.resblocks.10.attn.in_proj_bias', 'encoder.transformer.resblocks.10.attn.out_proj.weight', 'encoder.transformer.resblocks.10.attn.out_proj.bias', 'encoder.transformer.resblocks.10.ln_1.weight', 'encoder.transformer.resblocks.10.ln_1.bias', 'encoder.transformer.resblocks.10.mlp.c_fc.weight', 'encoder.transformer.resblocks.10.mlp.c_fc.bias', 'encoder.transformer.resblocks.10.mlp.c_proj.weight', 'encoder.transformer.resblocks.10.mlp.c_proj.bias', 'encoder.transformer.resblocks.10.ln_2.weight', 'encoder.transformer.resblocks.10.ln_2.bias', 'encoder.transformer.resblocks.11.attn.in_proj_weight', 'encoder.transformer.resblocks.11.attn.in_proj_bias', 'encoder.transformer.resblocks.11.attn.out_proj.weight', 'encoder.transformer.resblocks.11.attn.out_proj.bias', 'encoder.transformer.resblocks.11.ln_1.weight', 'encoder.transformer.resblocks.11.ln_1.bias', 'encoder.transformer.resblocks.11.mlp.c_fc.weight', 'encoder.transformer.resblocks.11.mlp.c_fc.bias', 'encoder.transformer.resblocks.11.mlp.c_proj.weight', 'encoder.transformer.resblocks.11.mlp.c_proj.bias', 'encoder.transformer.resblocks.11.ln_2.weight', 'encoder.transformer.resblocks.11.ln_2.bias', 'encoder.ln_post.weight', 'encoder.ln_post.bias', 'adapter.l0_k.0.weight', 'adapter.l0_k.2.weight', 'adapter.l0_k.2.bias', 'adapter.l0_k.3.weight', 'adapter.l0_v.0.weight', 'adapter.l0_v.2.weight', 'adapter.l0_v.2.bias', 'adapter.l0_v.3.weight', 'adapter.l1_k.0.weight', 'adapter.l1_k.2.weight', 'adapter.l1_k.2.bias', 'adapter.l1_k.3.weight', 'adapter.l1_v.0.weight', 'adapter.l1_v.2.weight', 'adapter.l1_v.2.bias', 'adapter.l1_v.3.weight', 'adapter.l2_k.0.weight', 'adapter.l2_k.2.weight', 'adapter.l2_k.2.bias', 'adapter.l2_k.3.weight', 'adapter.l2_v.0.weight', 'adapter.l2_v.2.weight', 'adapter.l2_v.2.bias', 'adapter.l2_v.3.weight', 'adapter.l3_k.0.weight', 'adapter.l3_k.2.weight', 'adapter.l3_k.2.bias', 'adapter.l3_k.3.weight', 'adapter.l3_v.0.weight', 'adapter.l3_v.2.weight', 'adapter.l3_v.2.bias', 'adapter.l3_v.3.weight', 'adapter.l4_k.0.weight', 'adapter.l4_k.2.weight', 'adapter.l4_k.2.bias', 'adapter.l4_k.3.weight', 'adapter.l4_v.0.weight', 'adapter.l4_v.2.weight', 'adapter.l4_v.2.bias', 'adapter.l4_v.3.weight', 'adapter.l5_k.0.weight', 'adapter.l5_k.2.weight', 'adapter.l5_k.2.bias', 'adapter.l5_k.3.weight', 'adapter.l5_v.0.weight', 'adapter.l5_v.2.weight', 'adapter.l5_v.2.bias', 'adapter.l5_v.3.weight'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m CompInvEncoder\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maccelerate\u001b[39;00m \u001b[39mimport\u001b[39;00m Accelerator\n\u001b[0;32m----> 3\u001b[0m m \u001b[39m=\u001b[39m CompInvEncoder(CompInvEncoder\u001b[39m.\u001b[39;49mget_default_config(),Accelerator())\n",
      "File \u001b[0;32m~/Desktop/repos/dfd-clip/src/models.py:406\u001b[0m, in \u001b[0;36mCompInvEncoder.__init__\u001b[0;34m(self, config, accelerator, *args, **kargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39massert\u001b[39;00m config\u001b[39m.\u001b[39mdecode_mode \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mstride\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    405\u001b[0m \u001b[39mwith\u001b[39;00m accelerator\u001b[39m.\u001b[39mmain_process_first():\n\u001b[0;32m--> 406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m disable_gradients(clip\u001b[39m.\u001b[39;49mload(config\u001b[39m.\u001b[39;49marchitecture)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvisual\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m    408\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode_mode \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mdecode_mode\n\u001b[1;32m    410\u001b[0m \u001b[39mif\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstride\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/repos/dfd-clip/src/clip/clip.py:139\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, device, jit, download_root)\u001b[0m\n\u001b[1;32m    136\u001b[0m         state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(opened_file, map_location\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m jit:\n\u001b[0;32m--> 139\u001b[0m     model \u001b[39m=\u001b[39m build_model(state_dict \u001b[39mor\u001b[39;49;00m model\u001b[39m.\u001b[39;49mstate_dict())\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m    140\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(device) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    141\u001b[0m         model\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/envs/dfd-clip/lib/python3.8/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/anaconda3/envs/dfd-clip/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dfd-clip/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dfd-clip/lib/python3.8/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/dfd-clip/lib/python3.8/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "from src.models import CompInvEncoder\n",
    "from accelerate import Accelerator\n",
    "m = CompInvEncoder(CompInvEncoder.get_default_config(),Accelerator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.load_state_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder.class_embedding', 'encoder.positional_embedding', 'encoder.proj', 'encoder.conv1.weight', 'encoder.ln_pre.weight', 'encoder.ln_pre.bias', 'encoder.transformer.resblocks.0.attn.in_proj_weight', 'encoder.transformer.resblocks.0.attn.in_proj_bias', 'encoder.transformer.resblocks.0.attn.out_proj.weight', 'encoder.transformer.resblocks.0.attn.out_proj.bias', 'encoder.transformer.resblocks.0.ln_1.weight', 'encoder.transformer.resblocks.0.ln_1.bias', 'encoder.transformer.resblocks.0.mlp.c_fc.weight', 'encoder.transformer.resblocks.0.mlp.c_fc.bias', 'encoder.transformer.resblocks.0.mlp.c_proj.weight', 'encoder.transformer.resblocks.0.mlp.c_proj.bias', 'encoder.transformer.resblocks.0.ln_2.weight', 'encoder.transformer.resblocks.0.ln_2.bias', 'encoder.transformer.resblocks.1.attn.in_proj_weight', 'encoder.transformer.resblocks.1.attn.in_proj_bias', 'encoder.transformer.resblocks.1.attn.out_proj.weight', 'encoder.transformer.resblocks.1.attn.out_proj.bias', 'encoder.transformer.resblocks.1.ln_1.weight', 'encoder.transformer.resblocks.1.ln_1.bias', 'encoder.transformer.resblocks.1.mlp.c_fc.weight', 'encoder.transformer.resblocks.1.mlp.c_fc.bias', 'encoder.transformer.resblocks.1.mlp.c_proj.weight', 'encoder.transformer.resblocks.1.mlp.c_proj.bias', 'encoder.transformer.resblocks.1.ln_2.weight', 'encoder.transformer.resblocks.1.ln_2.bias', 'encoder.transformer.resblocks.2.attn.in_proj_weight', 'encoder.transformer.resblocks.2.attn.in_proj_bias', 'encoder.transformer.resblocks.2.attn.out_proj.weight', 'encoder.transformer.resblocks.2.attn.out_proj.bias', 'encoder.transformer.resblocks.2.ln_1.weight', 'encoder.transformer.resblocks.2.ln_1.bias', 'encoder.transformer.resblocks.2.mlp.c_fc.weight', 'encoder.transformer.resblocks.2.mlp.c_fc.bias', 'encoder.transformer.resblocks.2.mlp.c_proj.weight', 'encoder.transformer.resblocks.2.mlp.c_proj.bias', 'encoder.transformer.resblocks.2.ln_2.weight', 'encoder.transformer.resblocks.2.ln_2.bias', 'encoder.transformer.resblocks.3.attn.in_proj_weight', 'encoder.transformer.resblocks.3.attn.in_proj_bias', 'encoder.transformer.resblocks.3.attn.out_proj.weight', 'encoder.transformer.resblocks.3.attn.out_proj.bias', 'encoder.transformer.resblocks.3.ln_1.weight', 'encoder.transformer.resblocks.3.ln_1.bias', 'encoder.transformer.resblocks.3.mlp.c_fc.weight', 'encoder.transformer.resblocks.3.mlp.c_fc.bias', 'encoder.transformer.resblocks.3.mlp.c_proj.weight', 'encoder.transformer.resblocks.3.mlp.c_proj.bias', 'encoder.transformer.resblocks.3.ln_2.weight', 'encoder.transformer.resblocks.3.ln_2.bias', 'encoder.transformer.resblocks.4.attn.in_proj_weight', 'encoder.transformer.resblocks.4.attn.in_proj_bias', 'encoder.transformer.resblocks.4.attn.out_proj.weight', 'encoder.transformer.resblocks.4.attn.out_proj.bias', 'encoder.transformer.resblocks.4.ln_1.weight', 'encoder.transformer.resblocks.4.ln_1.bias', 'encoder.transformer.resblocks.4.mlp.c_fc.weight', 'encoder.transformer.resblocks.4.mlp.c_fc.bias', 'encoder.transformer.resblocks.4.mlp.c_proj.weight', 'encoder.transformer.resblocks.4.mlp.c_proj.bias', 'encoder.transformer.resblocks.4.ln_2.weight', 'encoder.transformer.resblocks.4.ln_2.bias', 'encoder.transformer.resblocks.5.attn.in_proj_weight', 'encoder.transformer.resblocks.5.attn.in_proj_bias', 'encoder.transformer.resblocks.5.attn.out_proj.weight', 'encoder.transformer.resblocks.5.attn.out_proj.bias', 'encoder.transformer.resblocks.5.ln_1.weight', 'encoder.transformer.resblocks.5.ln_1.bias', 'encoder.transformer.resblocks.5.mlp.c_fc.weight', 'encoder.transformer.resblocks.5.mlp.c_fc.bias', 'encoder.transformer.resblocks.5.mlp.c_proj.weight', 'encoder.transformer.resblocks.5.mlp.c_proj.bias', 'encoder.transformer.resblocks.5.ln_2.weight', 'encoder.transformer.resblocks.5.ln_2.bias', 'encoder.transformer.resblocks.6.attn.in_proj_weight', 'encoder.transformer.resblocks.6.attn.in_proj_bias', 'encoder.transformer.resblocks.6.attn.out_proj.weight', 'encoder.transformer.resblocks.6.attn.out_proj.bias', 'encoder.transformer.resblocks.6.ln_1.weight', 'encoder.transformer.resblocks.6.ln_1.bias', 'encoder.transformer.resblocks.6.mlp.c_fc.weight', 'encoder.transformer.resblocks.6.mlp.c_fc.bias', 'encoder.transformer.resblocks.6.mlp.c_proj.weight', 'encoder.transformer.resblocks.6.mlp.c_proj.bias', 'encoder.transformer.resblocks.6.ln_2.weight', 'encoder.transformer.resblocks.6.ln_2.bias', 'encoder.transformer.resblocks.7.attn.in_proj_weight', 'encoder.transformer.resblocks.7.attn.in_proj_bias', 'encoder.transformer.resblocks.7.attn.out_proj.weight', 'encoder.transformer.resblocks.7.attn.out_proj.bias', 'encoder.transformer.resblocks.7.ln_1.weight', 'encoder.transformer.resblocks.7.ln_1.bias', 'encoder.transformer.resblocks.7.mlp.c_fc.weight', 'encoder.transformer.resblocks.7.mlp.c_fc.bias', 'encoder.transformer.resblocks.7.mlp.c_proj.weight', 'encoder.transformer.resblocks.7.mlp.c_proj.bias', 'encoder.transformer.resblocks.7.ln_2.weight', 'encoder.transformer.resblocks.7.ln_2.bias', 'encoder.transformer.resblocks.8.attn.in_proj_weight', 'encoder.transformer.resblocks.8.attn.in_proj_bias', 'encoder.transformer.resblocks.8.attn.out_proj.weight', 'encoder.transformer.resblocks.8.attn.out_proj.bias', 'encoder.transformer.resblocks.8.ln_1.weight', 'encoder.transformer.resblocks.8.ln_1.bias', 'encoder.transformer.resblocks.8.mlp.c_fc.weight', 'encoder.transformer.resblocks.8.mlp.c_fc.bias', 'encoder.transformer.resblocks.8.mlp.c_proj.weight', 'encoder.transformer.resblocks.8.mlp.c_proj.bias', 'encoder.transformer.resblocks.8.ln_2.weight', 'encoder.transformer.resblocks.8.ln_2.bias', 'encoder.transformer.resblocks.9.attn.in_proj_weight', 'encoder.transformer.resblocks.9.attn.in_proj_bias', 'encoder.transformer.resblocks.9.attn.out_proj.weight', 'encoder.transformer.resblocks.9.attn.out_proj.bias', 'encoder.transformer.resblocks.9.ln_1.weight', 'encoder.transformer.resblocks.9.ln_1.bias', 'encoder.transformer.resblocks.9.mlp.c_fc.weight', 'encoder.transformer.resblocks.9.mlp.c_fc.bias', 'encoder.transformer.resblocks.9.mlp.c_proj.weight', 'encoder.transformer.resblocks.9.mlp.c_proj.bias', 'encoder.transformer.resblocks.9.ln_2.weight', 'encoder.transformer.resblocks.9.ln_2.bias', 'encoder.transformer.resblocks.10.attn.in_proj_weight', 'encoder.transformer.resblocks.10.attn.in_proj_bias', 'encoder.transformer.resblocks.10.attn.out_proj.weight', 'encoder.transformer.resblocks.10.attn.out_proj.bias', 'encoder.transformer.resblocks.10.ln_1.weight', 'encoder.transformer.resblocks.10.ln_1.bias', 'encoder.transformer.resblocks.10.mlp.c_fc.weight', 'encoder.transformer.resblocks.10.mlp.c_fc.bias', 'encoder.transformer.resblocks.10.mlp.c_proj.weight', 'encoder.transformer.resblocks.10.mlp.c_proj.bias', 'encoder.transformer.resblocks.10.ln_2.weight', 'encoder.transformer.resblocks.10.ln_2.bias', 'encoder.transformer.resblocks.11.attn.in_proj_weight', 'encoder.transformer.resblocks.11.attn.in_proj_bias', 'encoder.transformer.resblocks.11.attn.out_proj.weight', 'encoder.transformer.resblocks.11.attn.out_proj.bias', 'encoder.transformer.resblocks.11.ln_1.weight', 'encoder.transformer.resblocks.11.ln_1.bias', 'encoder.transformer.resblocks.11.mlp.c_fc.weight', 'encoder.transformer.resblocks.11.mlp.c_fc.bias', 'encoder.transformer.resblocks.11.mlp.c_proj.weight', 'encoder.transformer.resblocks.11.mlp.c_proj.bias', 'encoder.transformer.resblocks.11.ln_2.weight', 'encoder.transformer.resblocks.11.ln_2.bias', 'encoder.ln_post.weight', 'encoder.ln_post.bias', 'adapter.l0_k.0.weight', 'adapter.l0_k.2.weight', 'adapter.l0_k.2.bias', 'adapter.l0_k.3.weight', 'adapter.l0_v.0.weight', 'adapter.l0_v.2.weight', 'adapter.l0_v.2.bias', 'adapter.l0_v.3.weight', 'adapter.l1_k.0.weight', 'adapter.l1_k.2.weight', 'adapter.l1_k.2.bias', 'adapter.l1_k.3.weight', 'adapter.l1_v.0.weight', 'adapter.l1_v.2.weight', 'adapter.l1_v.2.bias', 'adapter.l1_v.3.weight', 'adapter.l2_k.0.weight', 'adapter.l2_k.2.weight', 'adapter.l2_k.2.bias', 'adapter.l2_k.3.weight', 'adapter.l2_v.0.weight', 'adapter.l2_v.2.weight', 'adapter.l2_v.2.bias', 'adapter.l2_v.3.weight', 'adapter.l3_k.0.weight', 'adapter.l3_k.2.weight', 'adapter.l3_k.2.bias', 'adapter.l3_k.3.weight', 'adapter.l3_v.0.weight', 'adapter.l3_v.2.weight', 'adapter.l3_v.2.bias', 'adapter.l3_v.3.weight', 'adapter.l4_k.0.weight', 'adapter.l4_k.2.weight', 'adapter.l4_k.2.bias', 'adapter.l4_k.3.weight', 'adapter.l4_v.0.weight', 'adapter.l4_v.2.weight', 'adapter.l4_v.2.bias', 'adapter.l4_v.3.weight', 'adapter.l5_k.0.weight', 'adapter.l5_k.2.weight', 'adapter.l5_k.2.bias', 'adapter.l5_k.3.weight', 'adapter.l5_v.0.weight', 'adapter.l5_v.2.weight', 'adapter.l5_v.2.bias', 'adapter.l5_v.3.weight'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  '.'.join(k.split('.')[1:]):v  for k,v in  data.items() if \"adapter\"  in k\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "m.adapter.load_state_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfd-clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
