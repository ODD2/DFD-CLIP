diff --git a/src/datasets.py b/src/datasets.py
index 7ed9022..25d83b6 100644
--- a/src/datasets.py
+++ b/src/datasets.py
@@ -27,22 +27,22 @@ class FFPP(Dataset):
     def get_default_config():
         C = CN()
         C.name = 'train'
-        C.root_dir = '/home/ernestchu/scratch4/Datasets/FFPP'
+        C.root_dir = './datasets/ffpp/'
         C.types = ['REAL', 'DF']
         C.compressions = ['raw']
         C.detection_level = 'video'
-        C.num_frames = 30
+        C.dataset = "FFPP"
         return C
 
-    def __init__(self, config, transform, accelerator, split='train'):
+    def __init__(self, config,num_frames,clip_duration, transform, accelerator, split='train'):
         self.TYPE_DIRS = {
-            'REAL': 'data/original_sequences/youtube/',
+            'REAL': 'real/',
             # 'DFD' : 'data/original_sequences/actors/',
-            'DF'  : 'data/manipulated_sequences/Deepfakes/',
-            'FS'  : 'data/manipulated_sequences/FaceSwap/',
-            'F2F' : 'data/manipulated_sequences/Face2Face/',
-            'NT'  : 'data/manipulated_sequences/NeuralTextures/',
-            'FSH' : 'data/manipulated_sequences/FaceShifter/',
+            'DF'  : 'DF/',
+            'FS'  : 'FS/',
+            'F2F' : 'F2F/',
+            'NT'  : 'NT/',
+            # 'FSH' : 'data/manipulated_sequences/FaceShifter/',
             # 'DFD-FAKE' : 'data/manipulated_sequences/DeepFakeDetection/',
         }
         self.name = config.name
@@ -50,10 +50,14 @@ class FFPP(Dataset):
         self.detection_level = config.detection_level
         self.types = config.types
         self.compressions = config.compressions
-        self.num_frames = config.num_frames
+        self.num_frames = num_frames
+        self.clip_duration = clip_duration
         self.split = split
         self.transform = transform
-        with accelerator.main_process_first():
+        if accelerator:
+            with accelerator.main_process_first():
+                self._build_video_table(accelerator)
+        else:
             self._build_video_table(accelerator)
         self._build_data_list(accelerator)
 
@@ -69,7 +73,7 @@ class FFPP(Dataset):
         df_type, comp, idx = self.data_list[idx]
         video_clips = self.video_table[df_type][comp][idx]
         clip  = random.choice(video_clips)
-        reader = VideoReader(path.join(self.root, self.TYPE_DIRS[df_type], comp, 'videos', idx, f'{clip}.avi'), "video")
+        reader = VideoReader(path.join(self.root, comp, 'videos', self.TYPE_DIRS[df_type], idx, f'{clip}.avi'), "video")
         metadata = reader.get_metadata()
         if self.detection_level == 'frame':
             frame = None
@@ -112,26 +116,30 @@ class FFPP(Dataset):
 
     def _build_video_table(self, accelerator):
         self.video_table = {}
-
+        print('test','123')
         progress_bar = tqdm(self.types, disable=not accelerator.is_local_main_process)
         for df_type in progress_bar:
+            print('test','456')
             self.video_table[df_type] = {}
             for comp in self.compressions:
+                print('test','789')
                 video_cache = path.expanduser(f'~/.cache/dfd-clip/videos/{df_type}-{comp}.pkl')
-                if path.isfile(video_cache):
-                    with open(video_cache, 'rb') as f:
-                        videos = pickle.load(f)
-                    self.video_table[df_type][comp] = videos
-                    continue
-
-                subdir = path.join(self.root, self.TYPE_DIRS[df_type], '')
+                # if path.isfile(video_cache):
+                #     with open(video_cache, 'rb') as f:
+                #         videos = pickle.load(f)
+                #     self.video_table[df_type][comp] = videos
+                #     continue
+                print('test','135')
+                subdir = path.join(self.root, comp, 'videos', self.TYPE_DIRS[df_type], '')
+                print("subdir",subdir)
                 # video table
-                videos = {f.name: [] for f in scandir(path.join(subdir, f'{comp}/videos')) if f.is_dir()}
+                videos = {f.name: [] for f in scandir(subdir) if f.is_dir()}
+                print('test',videos)
                 for fname in videos:
                     # clip list
                     videos[fname] = [
-                        f.name[:-4] for f in scandir(path.join(subdir, f'{comp}/videos', fname)) if '.avi' in f.name]
-                    progress_bar.set_description(f"{df_type}: {path.join(f'{comp}/videos', fname)}")
+                        f.name[:-4] for f in scandir(path.join(subdir,  fname)) if '.avi' in f.name]
+                    progress_bar.set_description(f"{df_type}: {path.join(subdir, fname)}")
 
                 if accelerator.is_local_main_process:
                     makedirs(path.dirname(video_cache), exist_ok=True)
@@ -154,7 +162,7 @@ class FFPP(Dataset):
                     if idx in self.video_table[df_type][comp]:
                         self.data_list.append((df_type, comp, idx))
                     else:
-                        accelerator.print(f'Warning: video {path.join(self.root, self.TYPE_DIRS[df_type], comp, "videos", idx)} does not present in the processed dataset.')
+                        accelerator.print(f'Warning: video {path.join(self.root, comp, "videos", self.TYPE_DIRS[df_type], idx)} does not present in the processed dataset.')
 
     def _get_test_item(self, idx):
         df_type, comp, idx = self.data_list[idx]
@@ -165,7 +173,7 @@ class FFPP(Dataset):
             clips = []
             masks = []
             for clip in video_clips:
-                reader = VideoReader(path.join(self.root, self.TYPE_DIRS[df_type], comp, 'videos', idx, f'{clip}.avi'), "video")
+                reader = VideoReader(path.join(self.root, comp, 'videos', self.TYPE_DIRS[df_type], idx, f'{clip}.avi'), "video")
                 frames = []
                 count = 0
                 for frame in reader:
@@ -339,20 +347,19 @@ class RPPG(Dataset):
         C.name = 'train'
         C.root_dir = './datasets/hci/'
         C.detection_level = 'video'
-        C.num_frames = 50
-        C.clip_duration = 10
         C.train_ratio = 0.95
         C.cropped_folder="cropped_faces"
         C.meta_folder="Metas"
+        C.dataset = "RPPG"
         return C
 
-    def __init__(self, config, transform=None, accelerator=None, split='train'):
+    def __init__(self, config,num_frames,clip_duration, transform=None, accelerator=None, split='train'):
         # TODO: accelerator not implemented
         self.name = config.name
         # HCI datasets recorded videos with 61 fps
         self.transform = transform
-        self.num_frames = config.num_frames
-        self.clip_duration = config.clip_duration
+        self.num_frames = num_frames
+        self.clip_duration = clip_duration
 
         # dataset consistency
         rng = random.Random()
