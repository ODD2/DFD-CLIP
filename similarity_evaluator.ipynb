{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import statistics\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from accelerate import Accelerator\n",
    "from yacs.config import CfgNode as CN\n",
    "from main import get_config, init_accelerator, set_seed, FFPP\n",
    "from src.models import Detector\n",
    "\n",
    "logging_fmt = \"[%(filename)s:%(lineno)d]: %(message)s\"\n",
    "logging.basicConfig(level=\"INFO\", format=logging_fmt)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run(\n",
    "    cfg_path,\n",
    "    num_frames=20,\n",
    "    df_types=[\"REAL\", \"NT\", \"FS\", \"F2F\", \"DF\"],\n",
    "    parts=[\"lips\", \"skin\"],\n",
    "):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    device = \"cuda\"\n",
    "\n",
    "    accelerator = Accelerator(mixed_precision=\"no\")\n",
    "\n",
    "    # instantiate model\n",
    "    with open(cfg_path) as f:\n",
    "        preset = CN(yaml.safe_load(f))\n",
    "\n",
    "    mc = Detector.get_default_config().merge_from_other_cfg(preset.model)\n",
    "    mc.op_mode.attn_record = True\n",
    "\n",
    "    model = Detector(mc, num_frames, accelerator).to(accelerator.device)\n",
    "    model.load_state_dict(\n",
    "        torch.load(\n",
    "            os.path.join(os.path.split(cfg_path)[0], \"best_weights.pt\"),\n",
    "            map_location=\"cpu\",\n",
    "        )\n",
    "    )\n",
    "    model.eval()\n",
    "    model = model.to(\"cuda\")\n",
    "\n",
    "    # instantiate data loader\n",
    "    c = FFPP.get_default_config()\n",
    "    c.pack = 1\n",
    "    c.augmentation = \"none\"\n",
    "    c.random_speed = False\n",
    "    c.compressions = [\"c23\"]\n",
    "    c.types = df_types\n",
    "\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.Resize(\n",
    "                model.encoder.input_resolution,\n",
    "                interpolation=T.InterpolationMode.BICUBIC,\n",
    "            ),\n",
    "            T.CenterCrop(model.encoder.input_resolution),\n",
    "            T.ConvertImageDtype(torch.float32),\n",
    "            T.Normalize(\n",
    "                (0.48145466, 0.4578275, 0.40821073),\n",
    "                (0.26862954, 0.26130258, 0.27577711),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    x = FFPP(c.clone(), num_frames, 4, transform, accelerator, split=\"test\")\n",
    "\n",
    "    # load semantic patch features according to decode layers.\n",
    "    with open(\"misc/semantic_patches.pickle\", \"rb\") as f:\n",
    "        prefetch_queries = pickle.load(f)\n",
    "        semantic_queries = []\n",
    "        for i in model.layer_indices:\n",
    "            features = []\n",
    "            for part in parts:\n",
    "                features.append(prefetch_queries[\"k\"][part][i])\n",
    "            semantic_queries.append(torch.stack(features))\n",
    "        semantic_queries = torch.stack(semantic_queries)\n",
    "\n",
    "    # sample video clip\n",
    "    vid_idx = random.randrange(0, len(x))\n",
    "    clips, label, masks, speed, meta, task_index = x[vid_idx]\n",
    "    clip = clips[0]\n",
    "    mask = masks[0]\n",
    "\n",
    "    # inference for layer_results and Qs\n",
    "    _, features = model.predict(\n",
    "        clip.unsqueeze(0).to(device), mask.unsqueeze(0).to(device)\n",
    "    )\n",
    "\n",
    "    # layer attention results\n",
    "    layer_results = features[\"layer_results\"]\n",
    "\n",
    "    # locate attention blocks\n",
    "    image_attn_blocks = list(\n",
    "        dict(model.decoder.transformer.resblocks.named_children()).values()\n",
    "    )\n",
    "\n",
    "    # traverse overall blocks\n",
    "    for i in range(len(image_attn_blocks)):\n",
    "        blk = image_attn_blocks[i]\n",
    "        logging.info(f\"# Layer:{i}\")\n",
    "\n",
    "        # similarity over all semantic queries of the current layer\n",
    "        logging.info(\n",
    "            \"## Semantic: {}\".format(\n",
    "                torch.nn.functional.cosine_similarity(\n",
    "                    semantic_queries[i].unsqueeze(1), semantic_queries[i], dim=-1\n",
    "                )\n",
    "                .abs()\n",
    "                .mean(1)\n",
    "                .flatten()\n",
    "                .tolist()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for _i, _q in enumerate(blk.attn.qs):\n",
    "            # _q has a shape of b,q,h,d\n",
    "            _q = _q.detach().cpu()\n",
    "            _q = _q.view(*_q.shape[:2], -1)\n",
    "            # since the number of batch must be 1 in this setting, we squeeze the tensor.\n",
    "            _q = _q.squeeze(0)  # _q now has shape q,h*d\n",
    "\n",
    "            logging.info(\n",
    "                \"## Q{} Cross: {}\".format(\n",
    "                    _i,\n",
    "                    torch.nn.functional.cosine_similarity(_q.unsqueeze(1), _q, dim=-1)\n",
    "                    .abs()\n",
    "                    .mean(1)\n",
    "                    .flatten()\n",
    "                    .tolist(),\n",
    "                )\n",
    "            )\n",
    "            logging.info(\n",
    "                \"## Q{} Semantic: {}\".format(\n",
    "                    _i,\n",
    "                    torch.nn.functional.cosine_similarity(\n",
    "                        _q, semantic_queries[i], dim=-1\n",
    "                    )\n",
    "                    .flatten()\n",
    "                    .tolist(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        r = layer_results[:, i].detach().cpu()\n",
    "        # since the number of batch must be 1 in this setting, we squeeze the tensor.\n",
    "        r = r.squeeze(0)\n",
    "\n",
    "        logging.info(\n",
    "            \"## Out Cross: {}\".format(\n",
    "                torch.nn.functional.cosine_similarity(r.unsqueeze(1), r, dim=-1)\n",
    "                .abs()\n",
    "                .mean(1)\n",
    "                .flatten()\n",
    "                .tolist()\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# none\n",
    "# cfg_path = \"logs/test/dark-night-989/setting.yaml\"\n",
    "\n",
    "# dissim\n",
    "# cfg_path = \"logs/test/divine-pond-998/setting.yaml\"\n",
    "\n",
    "# semantic v1\n",
    "# cfg_path = \"logs/test/hopeful-violet-1004/setting.yaml\"\n",
    "\n",
    "# semantic v1 + smax\n",
    "# cfg_path = \"logs/test/still-terrain-1023/setting.yaml\"\n",
    "\n",
    "# semantic v2 + smax\n",
    "# cfg_path = \"logs/test/iconic-dragon-1034/setting.yaml\"\n",
    "\n",
    "# semantic_v2,k + smax\n",
    "# cfg_path = \"logs/test/silver-gorge-1037/setting.yaml\"\n",
    "\n",
    "# semantic_v2,k(+nose) + smax\n",
    "# cfg_path = \"logs/test/mild-gorge-1039/setting.yaml\"\n",
    "\n",
    "# 5,semantic_v3.1,k + smax\n",
    "# cfg_path = \"logs/test/celestial-frost-1048/setting.yaml\"\n",
    "\n",
    "# 2,semantic_v2,k + smax, gpv2\n",
    "cfg_path = \"logs/test/restful-water-1095/setting.yaml\"\n",
    "\n",
    "\n",
    "# run(cfg_path, parts=[\"lips\", \"skin\", \"nose\", \"eyes\", \"eyebrows\"])\n",
    "# run(cfg_path, parts=[\"lips\", \"skin\", \"nose\"])\n",
    "run(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfd-clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
